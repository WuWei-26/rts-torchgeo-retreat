# rts_datamodule_retreat.py

import os
from typing import Any, Dict, List, Optional, Sequence, Tuple, Union

# from kornia import image_to_tensor, tensor_to_image
import kornia.augmentation as K
import matplotlib.pyplot as plt
import pytorch_lightning as pl
import rasterio

from pathlib import Path

# from pytorch_lightning.utilities.types import EVAL_DATALOADERS
import torch
from kornia.constants import Resample
from kornia.enhance import denormalize, normalize
from rasterio.crs import CRS
from torch import Tensor
from torch.utils.data import DataLoader
from torchgeo.datasets import (
    BoundingBox,
    IntersectionDataset,
    UnionDataset,
    stack_samples,
)
from torchgeo.samplers import Units

# import torchvision
from torchvision import transforms

from rts_dataset_retreat import (
    Landsat8SR,
    Landsat57SR,
    MeanTPI,
    RtsMask,
    TestIntersectionDEM,
    TestLandsat8SR,
    TestLandsat57SR,
    TestMeanTPI,
    RTSTemporalPairDataset,
    RetreatMapDataset,
)
from rts_sampler_retreat import RandomGeoSamplerMultiRoiMultiYear, TestPreChippedGeoSampler
from rts_utils import plot_batch

# torchvision.models.resnet18

if os.cpu_count() is not None:
    N_WORKERS = int(os.cpu_count() / 2)  # type: ignore
else:
    N_WORKERS = 4
DEM_NULL = -7
# Asia_North_Albers_Equal_Area_Conic from QGIS esri:102025
CRS_AEA = rasterio.CRS.from_proj4(
    "+proj=aea +lat_0=30 +lon_0=95 +lat_1=15 +lat_2=65 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs"
)

# mask the ground truth mask corresponding to non-data (cloud) & convert to float

RETREAT_SCALE =  28.90128517150879 # global_max retreat = 28.90128517150879
# RETREAT_SCALE =  1.0 # dont scale

# TODO: mask portion of DEM pixels
# add noise, alter brightness
class DataAugmentation(torch.nn.Module):
    """Module to perform data augmentation using Kornia on torch tensors."""

    def __init__(self, patch_size=(256, 256), p=0.5) -> None:
        super().__init__()
        self.transforms = K.AugmentationSequential(
            K.RandomHorizontalFlip(p=p),
            K.RandomVerticalFlip(p=p),
            # range of degrees to select from (-degrees, +degrees)
            K.RandomRotation(
                degrees=45,
                resample=Resample.NEAREST.name,
                align_corners=None,  # can only be None for Nearest resampling # type: ignore
                p=p,
            ),
            # K.RandomResizedCrop(
            #     size=patch_size,
            #     scale=(0.5, 1.0),
            #     ratio=(0.9, 1.1),
            #     resample=Resample.NEAREST.name,
            #     align_corners=None,  # can only be None for Nearest resampling
            #     p=p
            # ),
            # < 1 darker, > 1 brighter, factor = bright_ness - 1, img_adjust: Tensor = image + factor,
            # img_adjust = img_adjust.clamp(min=0.0, max=1.0), need to do before normalize
            K.RandomBrightness(brightness=(0.95, 1.05), p=p),
            K.RandomGaussianNoise(mean=0.0, std=0.01, p=p),
            data_keys=["image", "mask"],
        )
        # self.aug_dem = K.RandomErasing(scale=(0.02, 0.33), value=DEM_NULL, p=1)
        self.aug_dem = K.RandomGaussianNoise(mean=0.0, std=0.1, p=p)

    @torch.no_grad()  # disable gradients for effiency
    def forward(self, sample_batch: dict) -> Dict[str, Tensor]:
        image = sample_batch["image"]
        mask = sample_batch["mask"]
        image, mask = self.transforms(image, mask)
        mask = mask.clone()
        dem_input = mask[:, 2, ...].clone() 
        mask[:, 2, ...] = self.aug_dem(dem_input)
        # mask[:, 2, ...] = self.aug_dem(mask[:, 2, ...])
        return {"image": image, "mask": mask}

class DataAugmentationPair(torch.nn.Module):
    def __init__(self, patch_size=(256, 256), p=0.5) -> None:
        super().__init__()
        self.geom = K.AugmentationSequential(
            K.RandomHorizontalFlip(p=p),
            K.RandomVerticalFlip(p=p),
            K.RandomRotation(degrees=45, resample=Resample.NEAREST.name, align_corners=None, p=p),
            K.RandomBrightness(brightness=(0.95, 1.05), p=p),
            K.RandomGaussianNoise(mean=0.0, std=0.01, p=p),
            data_keys=["input"],
            same_on_batch=True,
        )
        self.aug_dem = K.RandomGaussianNoise(mean=0.0, std=0.1, p=p)

    @torch.no_grad()
    def forward(self, sample: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        # 1) å–ä¸¤æ—¶ç›¸å½±åƒ
        img_t = sample["image_t"]   # [B, C, H, W]
        img_tm1 = sample["image_tm1"] # [B, C, H, W]
        B = img_t.shape[0]

        # 2) åœ¨ batch ç»´æ‹¼æ¥ â†’ åŒä¸€è°ƒç”¨ä¸­ä½¿ç”¨ç›¸åŒéšæœºå‚æ•°
        combined = torch.cat([img_t, img_tm1], dim=0)  # [2B, C, H, W]
        combined_aug = self.geom(combined)              # [2B, C, H, W]

        # 3) åˆ‡åˆ†å›ä¸¤æ—¶ç›¸
        sample["image_t"] = combined_aug[:B]
        sample["image_tm1"] = combined_aug[B:]

        # 4) DEM/TPI ä¸åšå‡ ä½•å˜æ¢ï¼Œä»…åŠ å™ªå£°ï¼ˆå¯é€‰ï¼‰
        if "dem_t" in sample:
            sample["dem_t"] = self.aug_dem(sample["dem_t"])
        if "dem_tm1" in sample:
            sample["dem_tm1"] = self.aug_dem(sample["dem_tm1"])

        return sample

class BandsNormalize(torch.nn.Module):
    """Normalize a tensor image with mean and standard deviation."""

    def __init__(
        self,
        mean: Union[Tensor, Tuple[float], List[float], float],
        std: Union[Tensor, Tuple[float], List[float], float],
    ) -> None:
        super().__init__()

        if isinstance(mean, (int, float)):
            mean = torch.tensor([mean])

        if isinstance(std, (int, float)):
            std = torch.tensor([std])

        if isinstance(mean, (tuple, list)):
            mean = torch.tensor(mean)[None]

        if isinstance(std, (tuple, list)):
            std = torch.tensor(std)[None]

        self.mean = mean
        self.std = std

    def forward(self, sample: dict) -> dict:
        image = sample["image"]
        # mean = self.mean.view(-1, 1, 1)
        # std = self.std.view(-1, 1, 1)
        image = normalize(image, self.mean, self.std)
        # image = (image - mean) / std
        sample["image"] = image
        return sample

class BandsNormalizePair(torch.nn.Module):
    def __init__(self, mean: Union[Tensor, Tuple[float], List[float], float],
                 std: Union[Tensor, Tuple[float], List[float], float]) -> None:
        super().__init__()
        if isinstance(mean, (int, float)): mean = torch.tensor([mean])
        if isinstance(std, (int, float)):  std  = torch.tensor([std])
        if isinstance(mean, (tuple, list)): mean = torch.tensor(mean)[None]
        if isinstance(std, (tuple, list)):  std  = torch.tensor(std)[None]
        self.mean, self.std = mean, std

    def forward(self, sample: Dict[str, Tensor]) -> Dict[str, Tensor]:
        sample["image_t"]   = normalize(sample["image_t"],   self.mean, self.std)
        sample["image_tm1"] = normalize(sample["image_tm1"], self.mean, self.std)
        return sample

class BandsDenormalize(BandsNormalize):
    """Denormalize a tensor image with mean and standard deviation."""

    def forward(self, sample: dict) -> dict:
        image = sample["image"]
        # mean = self.mean.view(1, -1, 1, 1)
        # std = self.std.view(1, -1, 1, 1)
        image = denormalize(image, self.mean, self.std)
        # image = (image * std) + mean
        sample["image"] = image
        return sample

class BandsDenormalizePair(BandsNormalizePair):
    def forward(self, sample: Dict[str, Tensor]) -> Dict[str, Tensor]:
        sample["image_t"]   = denormalize(sample["image_t"],   self.mean, self.std)
        sample["image_tm1"] = denormalize(sample["image_tm1"], self.mean, self.std)
        return sample

class Preprocess(torch.nn.Module):
    """Module to perform pre-process on sample dictionary of torch tensors."""

    @torch.no_grad()  # disable gradients for effiency
    def forward(self, sample: dict) -> dict:
        image = sample["image"].float()
        image = torch.nan_to_num(image)
        # assert not torch.isnan(image).any()
        non_data_mask = image[1, :, :] == 0  # got mask before applying scale
        image = Landsat8SR.apply_scale(image)  # convert to 0-1
        sample["image"] = image

        if sample.get("mask") is not None:
            mask = sample["mask"].float()
            mask = torch.nan_to_num(mask)

            # TODO: separate the preprocess of dem from image dataset
            if mask.shape[0] >= 2:
                mask[0:2, non_data_mask] = 0  # mask first two bands
                # mask[2, non_data_mask] = -7  # for dem
                # if torch.isnan(mask[2, :, :]).any():
                #     mask[2, :, :] = torch.nan_to_num(
                #         mask[2, :, :], nan=DEM_NULL)  # replace nan as -7
                # assert not torch.isnan(mask[2, :, :]).any()
                # mask[2,:,:] = 0
                # mask[2,:,:] = mask[2,:,:]/1.5 # for segmentation to 0-1

                # for heatmap to 0-1 from 12 to 15 to 20 to 30 (no_gamma)
                mask[0, :, :] = mask[0, :, :] / 30
                mask[1, :, :] = mask[1, :, :] / 255  # for segmentation to 0-1

            # mask = np.nan_to_num(mask)

            sample["mask"] = mask

        # if sample.get("dem") is not None:
        #     dem = sample["dem"]
        #     dem[:,non_data_mask] = 0
        #     sample["dem"] = dem
        # del sample['crs']
        # del sample['bbox']
        return sample

class PreprocessPair(torch.nn.Module):
    @torch.no_grad()
    def forward(self, sample: dict) -> dict:
        # å½±åƒï¼ˆæ ‡å‡†åŒ–æ¯”ä¾‹ä½ å·²æœ‰ï¼‰
        for k in ["image_t", "image_tm1"]:
            if k in sample:
                x = sample[k].float()
                x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)
                # Landsat SR ç¼©æ”¾
                non_data_mask = (x[:,1] == 0) if x.dim()==4 else (x[1]==0)
                x = Landsat8SR.apply_scale(x)
                sample[k] = x

        # æ ‡ç­¾ï¼šheatmapã€maskã€retreat_map
        if "heatmap" in sample:
            hm = sample["heatmap"].float()
            hm = torch.nan_to_num(hm, nan=0.0, posinf=0.0, neginf=0.0)
            hm = torch.clamp(hm / 30.0, min=0.0, max=1.5)  # å½’ä¸€åˆ° ~[0,1.5]
            sample["heatmap"] = hm
        if "mask" in sample:
            mk = sample["mask"].float()
            mk = torch.nan_to_num(mk, nan=0.0, posinf=0.0, neginf=0.0)
            mk = torch.clamp(mk / 255.0, min=0.0, max=1.0) # 0/255 -> 0/1
            sample["mask"] = mk
        if "retreat_map" in sample:
            rt = sample["retreat_map"].float()
            rt = torch.nan_to_num(rt, nan=0.0, posinf=0.0, neginf=0.0)
            rt = rt / RETREAT_SCALE  # 
            rt = torch.clamp(rt, min=0.0)  # è·ç¦»/ç±³ æˆ– ç±³/å¹´ï¼Œä¿æŒéè´Ÿ
            sample["retreat_map"] = rt

        # TPI/DEMï¼šå¯¹ç§°æ˜¾ç¤ºã€ä½†è®­ç»ƒå‰å…ˆä¿è¯æœ‰é™
        for k in ["dem_t","dem_tm1"]:
            if k in sample:
                d = sample[k].float()
                d = torch.nan_to_num(d, nan=0.0, posinf=0.0, neginf=0.0)
                sample[k] = d
        return sample

class LandsatDataModule(pl.LightningDataModule):
    def __init__(
        self,
        img_dir: str,
        dem_dir: str,
        mask_dir: str,
        train_length: int,
        val_length: int,
        test_length: int,
        year_dict_train: Dict[Any, Sequence[int | float]],
        year_dict_val: Dict[Any, Sequence[int | float]],
        year_dict_test: Dict[Any, Sequence[int | float]],
        band_num: int = 3,
        use_dem: bool = True,
        batch_size: int = 32,
        patch_size: int = 256,
        crs: Optional[CRS] = None,
        res: Optional[float] = 30,
        use_l7: bool = False,
        retreat_dir: Optional[str] = None,
    ) -> None:
        super().__init__()
        self.img_dir = img_dir
        self.batch_size = batch_size
        self.patch_size = patch_size
        self.retreat_dir = retreat_dir

        if band_num == 3:
            self.landsat_bands_l89 = ["SR_B4", "SR_B3", "SR_B2"]
            self.landsat_bands_l57 = ["SR_B3", "SR_B2", "SR_B1"]
        elif band_num == 4:
            self.landsat_bands_l89 = ["SR_B2", "SR_B3", "SR_B4", "SR_B5"]
            self.landsat_bands_l57 = ["SR_B1", "SR_B2", "SR_B3", "SR_B4"]
        elif band_num == 6:
            self.landsat_bands_l89 = ["SR_B2", "SR_B3", "SR_B4", "SR_B5", "SR_B6", "SR_B7"]
            self.landsat_bands_l57 = ["SR_B1", "SR_B2", "SR_B3", "SR_B4", "SR_B5", "SR_B7"]
        else:
            raise ValueError(f"Unsupported band_num={band_num}")

        self.ds_l89 = Landsat8SR(root=img_dir, crs=crs, bands=self.landsat_bands_l89, res=res, cache=False)

        if use_l7:
            self.ds_l57 = Landsat57SR(root=img_dir, crs=crs, bands=self.landsat_bands_l57, res=res, cache=False)
            # ä¾› RTSTemporalPairDataset ç”¨äºç©ºé—´/æ—¶é—´ç´¢å¼•
            self.img_dataset = UnionDataset(self.ds_l89, self.ds_l57)
            stats_ds = self.ds_l89  # å½’ä¸€åŒ–ä¸ RGB ç´¢å¼•ç»Ÿä¸€ç”¨ L8/9 çš„ç»Ÿè®¡
        else:
            self.img_dataset = self.ds_l89
            stats_ds = self.ds_l89

        # ç”¨â€œåŸºå‡†æ•°æ®é›†â€å–ç»Ÿè®¡ä¸ RGB ç´¢å¼•ï¼ˆæ³¨æ„ï¼šä¸è¦ä» UnionDataset å–ï¼‰
        self.bands = stats_ds.bands
        self.rgb_indexes = stats_ds.rgb_indexes

        self.preprocess = PreprocessPair()  # å¯¹ image_t & image_tm1 åš SR ç¼©æ”¾ä¸æ ‡ç­¾ç¼©æ”¾
        self.augmentation = DataAugmentationPair(patch_size=(patch_size, patch_size), p=0.5)
        self.normalize = BandsNormalizePair(mean=stats_ds.bands_mean, std=stats_ds.bands_std)
        self.denormalize = BandsDenormalizePair(mean=stats_ds.bands_mean, std=stats_ds.bands_std)
        # ä¿ç•™ transform ç®¡çº¿æ¥å£ï¼ˆå¦‚æœä½ åœ¨ Dataset ä¸­è¿˜ä¼šç”¨åˆ°ï¼‰
        self.transform = transforms.Compose([self.preprocess])

        mask_bands = ["heatmap", "segment", "retreat"]
        self.mask_dataset = RtsMask(
            root=mask_dir, crs=crs, bands=mask_bands, res=res, cache=False, debug=False
            )

        if not use_dem:
            raise ValueError("RTSTemporalPairDataset éœ€è¦ dem_dsï¼ˆæ ‡å‡†åŒ– TPIï¼‰ã€‚è¯·è®¾ use_dem=Trueã€‚")
        dem_bands = ["mean_tpi"]
        self.dem_dataset = MeanTPI(root=dem_dir, crs=crs, bands=dem_bands, res=res, cache=False)

        # ç‹¬ç«‹çš„ retreat æ•°æ®é›†ï¼ˆå¯é€‰ï¼šç›´æ¥è¯»å– ~/ww_cryostore/BLH_heatmap/retreat_map_YYYY.tifï¼‰
        # æ³¨æ„ï¼šåªè¦è®¾ç½® crs/res ä¸ç›®æ ‡ç½‘æ ¼ä¸€è‡´ï¼ŒRasterDataset ä¼šåœ¨çº¿é‡æŠ•å½±åˆ°ç›®æ ‡çª—å£ã€‚
        if self.retreat_dir:
            self.retreat_dataset = RetreatMapDataset(
                root=self.retreat_dir,
                crs=crs,   # ä¾‹å¦‚ "EPSG:32646"
                res=res,   # ä¾‹å¦‚ 30
                cache=False
            )
        else:
            self.retreat_dataset = None


        self.dataset = RTSTemporalPairDataset(
            img_ds=self.img_dataset,
            mask_ds=self.mask_dataset,
            dem_ds=self.dem_dataset,
            retreat_ds=self.retreat_dataset,
            transforms=self.preprocess,  # æˆå¯¹é¢„å¤„ç†åœ¨ Dataset å†…ç”Ÿæ•ˆ
        )

        self.train_sampler = RandomGeoSamplerMultiRoiMultiYear(
            self.dataset,
            size=self.patch_size,
            stride=int(self.patch_size / 2),
            length=train_length,
            year_dict=year_dict_train,
            units=Units.PIXELS,
            pair=True,
            prev_delta=1,
        )
        self.val_sampler = RandomGeoSamplerMultiRoiMultiYear(
            self.dataset,
            size=self.patch_size,
            stride=int(self.patch_size / 2),
            length=val_length,
            year_dict=year_dict_val,
            units=Units.PIXELS,
            pair=True,
            prev_delta=1,
        )
        self.test_sampler = RandomGeoSamplerMultiRoiMultiYear(
            self.dataset,
            size=self.patch_size,
            stride=int(self.patch_size / 2),
            length=test_length,
            year_dict=year_dict_test,
            units=Units.PIXELS,
            pair=True,
            prev_delta=1,
        )
        self.demo_sampler = RandomGeoSamplerMultiRoiMultiYear(
            self.dataset,
            size=self.patch_size,
            stride=int(self.patch_size / 2),
            length=self.batch_size,
            year_dict=year_dict_test,
            units=Units.PIXELS,
            pair=True,
            prev_delta=1,
        )

    def prepare_data(self):
        pass

    def setup(self, stage=None):
        # Assign train/val datasets for use in dataloaders
        # if stage == "fit" or stage is None:
        #     mnist_full = MNIST(self.data_dir, train=True,
        #                        transform=self.transform)
        #     self.mnist_train, self.mnist_val = random_split(
        #         mnist_full, [55000, 5000])

        # Assign test dataset for use in dataloader(s)
        # if stage == "test" or stage is None:
        #     self.mnist_test = MNIST(
        #         self.data_dir, train=False, transform=self.transform)
        pass

    def train_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.train_sampler,
            num_workers=N_WORKERS,
            batch_size=self.batch_size,
            collate_fn=stack_samples,
        )

    def val_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.val_sampler,
            num_workers=N_WORKERS,
            batch_size=self.batch_size,
            collate_fn=stack_samples,
        )

    def test_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.test_sampler,
            num_workers=N_WORKERS,
            batch_size=self.batch_size,
            collate_fn=stack_samples,
        )

    def predict_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.demo_sampler,
            num_workers=N_WORKERS,
            batch_size=self.batch_size,
            collate_fn=stack_samples,
        )

    def on_after_batch_transfer(self, batch, dataloader_idx):
        # only perform augmentation during training
        if self.trainer and self.trainer.training:
            # perform GPU/Batched data augmentation
            batch = self.augmentation(batch)
        batch = self.normalize(batch)
        return batch

    def transfer_batch_to_device(
        self, batch: Dict[str, Tensor], device: torch.device, dataloader_idx: int
    ) -> Dict[str, Tensor]:
        """Transfer batch to device.

        Defines how custom data types are moved to the target device.

        Args:
            batch: A batch of data that needs to be transferred to a new device.
            device: The target device as defined in PyTorch.
            dataloader_idx: The index of the dataloader to which the batch belongs.

        Returns:
            A reference to the data on the new device.
        """
        # Non-Tensor values cannot be moved to a device
        # TODO: convert bbox to tensor for later usage
        # if "crs" in batch.keys():
        #     del batch["crs"]
        # if "bbox" in batch.keys():
        #     del batch["bbox"]

        tensor_keys = ["image_t","image_tm1","dem_t","dem_tm1","mask","heatmap","retreat_map"]
        batch_tensors = {k: v for k, v in batch.items() if k in tensor_keys}
        batch_tensors = super().transfer_batch_to_device(batch_tensors, device, dataloader_idx)
        return batch_tensors

    def show_batch(
        self,
        data_loader,
        sample_num: Optional[int] = None,
        bright: float = 3,
        width: int = 6,
    ):
        import matplotlib.pyplot as plt
        import numpy as np
        import torch

        def _ensure_loader(dl):
            return dl() if callable(dl) else dl

        def _batch_size_from_tensors(batch: dict) -> int:
            # ä» batch ä¸­ä»»æ„å¼ é‡è·å– batch ç»´å¤§å°
            for v in batch.values():
                if torch.is_tensor(v) and v.dim() >= 1:
                    return v.shape[0]
            return 0

        def _safe_len(x):
            return len(x) if isinstance(x, (list, tuple)) else 0

        plt.style.use("default")
        loader = _ensure_loader(data_loader)
        batch = next(iter(loader))

        # åŒæ—¶ç›¸åˆ¤æ–­
        is_pair = all(k in batch for k in ["image_t", "image_tm1", "heatmap", "mask", "retreat_map"])

        # å…ˆè®¡ç®— B/Nï¼Œé¿å…åç»­æ‰“å°æ—¶å‡ºç° N æœªå®šä¹‰
        B = _batch_size_from_tensors(batch)
        N = min(sample_num or 6, B) if B > 0 else 0

        # è‹¥æœ‰è·¯å¾„ä¿¡æ¯ï¼Œå…ˆæ‰“å°æ ¸éªŒï¼ˆæ­¤æ—¶å·²çŸ¥ Nï¼‰
        if "path_t" in batch and "path_tm1" in batch and N > 0:
            pt  = batch["path_t"]
            ptm = batch["path_tm1"]
            # å…¼å®¹ list/tupleï¼Œé¿å…è¶Šç•Œ
            npt  = _safe_len(pt)
            nptm = _safe_len(ptm)
            for i in range(N):
                if i < npt:
                    print(f"[paths] t={batch.get('year_t', ['?']*N)[i] if isinstance(batch.get('year_t'), (list, tuple, torch.Tensor)) else batch.get('year_t', '?')} -> {pt[i]}")
                if i < nptm:
                    print(f"[paths] t-1={batch.get('year_tm1', ['?']*N)[i] if isinstance(batch.get('year_tm1'), (list, tuple, torch.Tensor)) else batch.get('year_tm1', '?')} -> {ptm[i]}")

        if not is_pair:
            # å•æ—¶ç›¸å›é€€
            # batch_aug = self.augmentation(batch)
            batch_aug = batch # no rotation augmentation
            batch_aug = self.normalize(batch_aug)
            try:
                batch_vis = self.denormalize(batch_aug)
            except Exception:
                batch_vis = batch_aug

            print("Before augmentation:\n")
            print(batch["image"].shape)
            plot_batch(
                batch=batch,
                sample_num=sample_num,
                bright=bright,
                chnls=self.rgb_indexes,
                width=width,
            )
            plt.show()

            print("After augmentation:\n")
            plot_batch(
                batch=batch_vis,
                sample_num=sample_num,
                bright=bright,
                chnls=self.rgb_indexes,
                width=width,
            )
            plt.show()
            return

        # åŒæ—¶ç›¸å¢å¹¿/å½’ä¸€åŒ–ï¼ˆæˆå¯¹ï¼‰
        batch_aug = self.augmentation(batch)
        batch_aug = self.normalize(batch_aug)
        try:
            batch_vis = self.denormalize(batch_aug)
        except Exception:
            batch_vis = batch_aug

        img_t   = batch_vis["image_t"]      # [B, C, H, W]
        img_tm1 = batch_vis["image_tm1"]    # [B, C, H, W]
        heatmap = batch_vis["heatmap"]      # [B, 1, H, W]
        seg     = batch_vis["mask"]         # [B, 1, H, W]
        retreat = batch_vis["retreat_map"]  # [B, 1, H, W]
        dem_t_bf = batch.get("dem_t", None)

        # é‡æ–°è®¡ç®— B/Nï¼ˆä»¥é˜² batch augmentation æ”¹å˜ batch ç»´ï¼›é€šå¸¸ä¸ä¼šï¼‰
        B = img_t.shape[0]
        N = min(sample_num or 6, B)

        def _nz(t):
            try:
                return int((t>0).sum().item())
            except Exception:
                return -1

        print("Shapes:",
            "img_t", tuple(img_t.shape),
            "img_tm1", tuple(img_tm1.shape),
            "heatmap", tuple(heatmap.shape),
            "seg", tuple(seg.shape),
            "retreat", tuple(retreat.shape))

        for i in range(N):
            hm_i = heatmap[i] if heatmap.ndim==4 else heatmap[i:i+1]
            sg_i = seg[i]     if seg.ndim==4     else seg[i:i+1]
            rt_i = retreat[i] if retreat.ndim==4 else retreat[i:i+1]
            print(f"[{i}] nz(heatmap)={_nz(hm_i)} nz(seg)={_nz(sg_i)} nz(retreat)={_nz(rt_i)}")

        # å®‰å…¨å–å•é€šé“ï¼ˆè‹¥ç¼ºé€šé“åˆ™ç”¨é›¶å›¾å ä½ï¼‰
        def get_vis_ch(batch_tensor: torch.Tensor, i: int, fallback_hw=None) -> np.ndarray:
            if fallback_hw is None:
                fallback_hw = (img_t.shape[-2], img_t.shape[-1])
            fh, fw = fallback_hw
            if batch_tensor is None:
                return np.zeros((fh, fw), dtype=np.float32)
            if batch_tensor.ndim == 4:
                if batch_tensor.shape[1] >= 1:
                    return batch_tensor[i, 0].detach().cpu().numpy()
                else:
                    return np.zeros((fh, fw), dtype=np.float32)
            elif batch_tensor.ndim == 3:
                return batch_tensor[i].detach().cpu().numpy()
            else:
                return np.zeros((fh, fw), dtype=np.float32)

        # ä½œå›¾ï¼ˆåç»­é€»è¾‘ä¿æŒä¸å˜ï¼‰
        ncols = 5
        fig, axes = plt.subplots(N, ncols, figsize=(ncols * width, N * width / 2), squeeze=False)

        rgb_idx = self.rgb_indexes if hasattr(self, "rgb_indexes") else [2, 1, 0]
        def _rgb(img_chw: torch.Tensor) -> np.ndarray:
            arr = img_chw[rgb_idx,...].detach().cpu().numpy().transpose(1, 2, 0)
            return np.clip(arr * bright, 0, 1)

        for i in range(N):
            # year t RGB
            axes[i, 0].imshow(_rgb(img_t[i])); axes[i, 0].set_title("Year t RGB"); axes[i, 0].axis("off")
            # year t heatmap GT
            hm_i = get_vis_ch(heatmap, i)
            axes[i, 1].imshow(np.clip(hm_i, 0, 1.3), cmap="jet", vmin=0, vmax=1.3)
            axes[i, 1].set_title("Year t Heatmap GT"); axes[i, 1].axis("off")
            # year t-1 RGB
            axes[i, 2].imshow(_rgb(img_tm1[i])); axes[i, 2].set_title("Year t-1 RGB"); axes[i, 2].axis("off")
            # retreat GT
            ret_i = get_vis_ch(retreat, i)
            axes[i, 3].imshow(ret_i, cmap="turbo")
            axes[i, 3].set_title("Retreat GT"); axes[i, 3].axis("off")
            # TPI
            tpi_bf_i = get_vis_ch(dem_t_bf, i) if dem_t_bf is not None else np.zeros((img_t.shape[-2], img_t.shape[-1]), dtype=np.float32)
            import numpy as np
            if np.isfinite(tpi_bf_i).any():
                vmax_bf = max(abs(np.nanpercentile(tpi_bf_i, 99)), abs(np.nanpercentile(tpi_bf_i, 1)))
            else:
                vmax_bf = 2.0
            axes[i, 4].imshow(tpi_bf_i, cmap="gray", vmin=-vmax_bf, vmax=vmax_bf)
            axes[i, 4].set_title("TPI"); axes[i, 4].axis("off")

        plt.tight_layout()
        plt.show()


class LandsatPairInferenceDataModule(pl.LightningDataModule):
    def __init__(
        self,
        img_dir: str,
        year_t: int,
        year_tm1: int,
        roi: BoundingBox,
        dem_dir: Optional[str] = None,
        band_num: int = 4,
        use_dem: bool = True,
        batch_size: int = 1,
        patch_size: int = 256,
        crs: Optional[CRS] = None,
        res: Optional[float] = 30,
        use_l7: bool = True,
        num_workers: int = 0,       # æ¨ç†é˜¶æ®µå»ºè®®å•è¿›ç¨‹ï¼Œé¿å… GDAL+å¤šè¿›ç¨‹é˜»å¡
    ) -> None:
        super().__init__()
        self.img_dir = img_dir
        self.dem_dir = dem_dir
        self.batch_size = batch_size
        self.patch_size = patch_size
        self.num_workers = num_workers
        self.use_dem = use_dem
        self.year_t = year_t
        self.year_tm1 = year_tm1
        self.roi = roi

        # æˆå¯¹é¢„å¤„ç†/å½’ä¸€åŒ–ï¼ˆä¸åšå¢å¼ºï¼‰
        self.preprocess = PreprocessPair()  # å¯¹ image_t/image_tm1 åš SR ç¼©æ”¾ä¸æ ‡ç­¾ç¼©æ”¾
        # ç”¨ L8/9 ç»Ÿè®¡ä½œä¸ºå½’ä¸€åŒ–åŸºå‡†
        # å½±åƒæ•°æ®é›†ï¼ˆL8/9ï¼›å¦‚ use_l7=True åˆ™ Union åˆ° L57ï¼‰
        if band_num == 3:
            bands_l89 = ["SR_B4","SR_B3","SR_B2"]; bands_l57 = ["SR_B3","SR_B2","SR_B1"]
        elif band_num == 4:
            bands_l89 = ["SR_B2","SR_B3","SR_B4","SR_B5"]; bands_l57 = ["SR_B1","SR_B2","SR_B3","SR_B4"]
        elif band_num == 6:
            bands_l89 = ["SR_B2","SR_B3","SR_B4","SR_B5","SR_B6","SR_B7"]; bands_l57 = ["SR_B1","SR_B2","SR_B3","SR_B4","SR_B5","SR_B7"]
        else:
            raise ValueError(f"Unsupported band_num={band_num}")
        
        # ğŸ”§ å…³é”®ä¿®æ”¹ï¼šæ”¯æŒå¤šå¹´ä»½æ•°æ®é›†
        self.img_dataset = self._create_multi_year_dataset(
            img_dir, [year_t, year_tm1], bands_l89, bands_l57, crs, res, use_l7
        )

        # ds_l89 = TestLandsat8SR(root=img_dir, crs=crs, bands=bands_l89, res=res, cache=False)
        # if use_l7:
        #     ds_l57 = TestLandsat57SR(root=img_dir, crs=crs, bands=bands_l57, res=res, cache=False)
        #     self.img_dataset = UnionDataset(ds_l89, ds_l57)
        #     stats_ds = ds_l89
        # else:
        #     self.img_dataset = ds_l89
        #     stats_ds = ds_l89

        # âœ… åªåˆ›å»ºä¸€ä¸ªç”¨äºè·å–ç»Ÿè®¡ä¿¡æ¯çš„æ•°æ®é›†ï¼Œä¸è¦†ç›– self.img_dataset
        # stats_ds = TestLandsat8SR(root=img_dir, crs=crs, bands=bands_l89, res=res, cache=False)

        # âœ… ä»…ç”¨äºè·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼/æ ‡å‡†å·®ï¼‰ï¼Œä¸è¦†ç›– self.img_dataset
        try:
            stats_ds = TestLandsat8SR(root=img_dir, crs=crs, bands=bands_l89, res=res, cache=False)
        except Exception:
            # å¦‚æœ img_dir æœ¬èº«æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä» year_t ç›®å½•è·å–
            img_path = Path(img_dir)
            if img_path.name == 'test' and img_path.parent.name.isdigit():
                base_dir = img_path.parent.parent
            else:
                base_dir = img_path
            year_t_dir = base_dir / str(year_t) / "test"
            stats_ds = TestLandsat8SR(root=str(year_t_dir), crs=crs, bands=bands_l89, res=res, cache=False)

        self.bands = stats_ds.bands
        self.rgb_indexes = stats_ds.rgb_indexes

        # æˆå¯¹å½’ä¸€åŒ–ï¼ˆæ¨ç†é˜¶æ®µä¸åšå¢å¼ºï¼Œä»…å½’ä¸€åŒ–ï¼‰
        self.normalize = BandsNormalizePair(mean=stats_ds.bands_mean, std=stats_ds.bands_std)
        self.denormalize = BandsDenormalizePair(mean=stats_ds.bands_mean, std=stats_ds.bands_std)
        self.transform = self.preprocess  # åªåšé¢„å¤„ç†

        # DEM/TPIï¼ˆå¯é€‰ï¼‰
        if use_dem and dem_dir:
            dem_bands = ["mean_tpi"]
            self.dem_dataset = TestMeanTPI(root=dem_dir, crs=crs, bands=dem_bands, res=res, cache=False)
            ds_for_pair = TestIntersectionDEM(self.img_dataset, self.dem_dataset, transforms=self.transform)
        else:
            self.dem_dataset = None
            ds_for_pair = self.img_dataset  # ä»…å½±åƒ

        # æˆå¯¹æ¨ç†æ•°æ®é›†ï¼šåªè¯»å½±åƒä¸ DEMï¼Œä¸è¯»æ ‡ç­¾
        # å¤ç”¨è®­ç»ƒç‰ˆçš„æˆå¯¹æ•°æ®é›† RTSTemporalPairDataset ä¹Ÿå¯ï¼Œä½†æ¨ç†æ—¶é€šå¸¸ä¸éœ€è¦ heatmap/mask/retreat_map
        # è¿™é‡Œç›´æ¥ç”¨è®­ç»ƒç‰ˆ RTSTemporalPairDatasetï¼Œåªå– image_t/image_tm1/dem_t/dem_tm1 é”®ï¼ˆTransforms æˆå¯¹é¢„å¤„ç†ï¼‰
        self.dataset = RTSTemporalPairDataset(
            img_ds=self.img_dataset,       # ç”¨åŸå½±åƒæ•°æ®é›†ï¼ˆTestLandsat* æ”¯æŒ pathï¼‰
            mask_ds=None,                  # æ¨ç†ä¸éœ€è¦æ ‡ç­¾ï¼›RTSTemporalPairDatasetéœ€æ”¹ä¸ºå…è®¸ Noneï¼ˆæˆ–ç”¨ä½ å‰é¢æä¾›çš„ PairTemporalDatasetï¼‰
            dem_ds=self.dem_dataset,
            retreat_ds=None,
            transforms=self.preprocess,
            year_t=year_t,
            year_tm1=year_tm1,
        )

        # æ„é€ ä¸€ä¸ª year_dict/pair=True çš„é‡‡æ ·å™¨ï¼ˆåªé’ˆå¯¹ç»™å®š ROI å’Œå¹´ä»½å¯¹ï¼‰
        roi_dict = {
            # é‡‡æ ·å™¨éœ€è¦ä¸€ä¸ªâ€œå½¢å¦‚è®­ç»ƒçš„ ROI å­—å…¸â€ï¼Œè¿™é‡Œæ„é€ å•ä¸€æ¡ç›®
            str(self.year_t): {
                "cluster_id": [0],
                "roi": [BoundingBox(roi.minx, roi.maxx, roi.miny, roi.maxy, roi.mint, roi.maxt)],
                "weight": [1.0],
            }
        }
        year_dict = {"year": [self.year_t], "weight": [1.0], "roi": [roi_dict[str(self.year_t)]]}

        # self.predict_sampler = RandomGeoSamplerMultiRoiMultiYear(
        #     self.dataset,
        #     size=self.patch_size,
        #     stride=self.patch_size,
        #     length=200, # self.patch_size
        #     year_dict=year_dict,
        #     units=Units.PIXELS,
        #     pair=True,        # å…³é”®ï¼šè¿”å› {'bbox','year_t','year_tm1'}
        #     prev_delta=self.year_t - self.year_tm1 if (self.year_t - self.year_tm1) > 0 else 1,
        # )

        self.predict_sampler = TestPreChippedGeoSampler(
            self.dataset, 
            min_size=32 * 2, 
            roi=self.roi, 
            units=Units.PIXELS,
            year_t=year_t,
            year_tm1=year_tm1,
        )
    
    def _create_multi_year_dataset(self, img_dir, years, bands_l89, bands_l57, crs, res, use_l7):
        """åˆ›å»ºæ”¯æŒå¤šå¹´ä»½çš„æ•°æ®é›†"""
        
        print(f"ğŸ”§ åˆ›å»ºå¤šå¹´ä»½æ•°æ®é›†ï¼Œå¹´ä»½: {years}")
        
        # ä» img_dir æ¨æ–­åŸºç¡€ç›®å½•ç»“æ„
        img_path = Path(img_dir)
        
        # å¦‚æœ img_dir æ˜¯ /path/2016/test æ ¼å¼ï¼Œéœ€è¦å›åˆ°åŸºç¡€ç›®å½•
        if img_path.name == 'test' and img_path.parent.name.isdigit():
            base_dir = img_path.parent.parent
            print(f"æ£€æµ‹åˆ°å¹´ä»½ç›®å½•ç»“æ„ï¼ŒåŸºç¡€ç›®å½•: {base_dir}")
        else:
            # å¦‚æœ img_dir å°±æ˜¯åŸºç¡€ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨
            base_dir = img_path
            print(f"ä½¿ç”¨åŸºç¡€ç›®å½•: {base_dir}")
        
        # æ”¶é›†æ‰€æœ‰å¹´ä»½çš„æ•°æ®é›†
        l89_datasets = []
        l57_datasets = []
        
        for year in years:
            year_dir = base_dir / str(year) / "test"
            
            if year_dir.exists():
                print(f"  æ·»åŠ å¹´ä»½ {year}: {year_dir}")
                
                # L8/9 æ•°æ®é›†
                try:
                    ds_l89 = TestLandsat8SR(
                        root=str(year_dir), 
                        crs=crs, 
                        bands=bands_l89, 
                        res=res, 
                        cache=False
                    )
                    l89_datasets.append(ds_l89)
                    print(f"    L8/9 æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œè¾¹ç•Œ: {ds_l89.bounds}")
                except Exception as e:
                    print(f"    âš ï¸ L8/9 æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
                
                # L5/7 æ•°æ®é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if use_l7:
                    try:
                        ds_l57 = TestLandsat57SR(
                            root=str(year_dir), 
                            crs=crs, 
                            bands=bands_l57, 
                            res=res, 
                            cache=False
                        )
                        l57_datasets.append(ds_l57)
                        print(f"    L5/7 æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
                    except Exception as e:
                        print(f"    âš ï¸ L5/7 æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
            else:
                print(f"  âŒ å¹´ä»½ {year} ç›®å½•ä¸å­˜åœ¨: {year_dir}")
        
        # åˆå¹¶æ•°æ®é›†
        if not l89_datasets:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„L8/9æ•°æ®é›†ï¼Œå¹´ä»½: {years}")
        
        # åˆå¹¶L8/9æ•°æ®é›†
        if len(l89_datasets) == 1:
            combined_l89 = l89_datasets[0]
        else:
            combined_l89 = UnionDataset(*l89_datasets)
        
        # å¦‚æœéœ€è¦L5/7ï¼Œè¿›ä¸€æ­¥åˆå¹¶
        if use_l7 and l57_datasets:
            if len(l57_datasets) == 1:
                combined_l57 = l57_datasets[0]
            else:
                combined_l57 = UnionDataset(*l57_datasets)
            
            final_dataset = UnionDataset(combined_l89, combined_l57)
            print(f"æœ€ç»ˆåˆå¹¶æ•°æ®é›† (L8/9 + L5/7)ï¼Œè¾¹ç•Œ: {final_dataset.bounds}")
        else:
            final_dataset = combined_l89
            print(f"æœ€ç»ˆæ•°æ®é›† (ä»…L8/9)ï¼Œè¾¹ç•Œ: {final_dataset.bounds}")
        
        return final_dataset

    def on_after_batch_transfer(self, batch, dataloader_idx):
        # æ¨ç†é˜¶æ®µä¸åšå¢å¹¿ï¼šä»…å½’ä¸€åŒ–æˆå¯¹å½±åƒ
        batch = self.normalize(batch)
        return batch

    def transfer_batch_to_device(self, batch: Dict[str, Tensor], device: torch.device, dataloader_idx: int) -> Dict[str, Tensor]:
        """åªç§»åŠ¨å¼ é‡åˆ°è®¾å¤‡ï¼Œä¿ç•™å…ƒæ•°æ®åœ¨CPUä¸Š"""
        
        # å®šä¹‰éœ€è¦ç§»åŠ¨åˆ°è®¾å¤‡çš„å¼ é‡å­—æ®µ
        tensor_keys = ["image_t", "image_tm1", "dem_t", "dem_tm1"]
        
        # å®šä¹‰éœ€è¦ä¿ç•™åœ¨CPUçš„å…ƒæ•°æ®å­—æ®µ
        metadata_keys = ["bbox", "path", "crs", "image"]
        
        # åˆ›å»ºæ–°çš„æ‰¹æ¬¡å­—å…¸
        new_batch = {}
        
        # ç§»åŠ¨å¼ é‡å­—æ®µåˆ°è®¾å¤‡
        for key in tensor_keys:
            if key in batch and torch.is_tensor(batch[key]):
                new_batch[key] = batch[key].to(device)
        
        # ä¿ç•™å…ƒæ•°æ®å­—æ®µåœ¨CPUï¼ˆä¸ç§»åŠ¨ï¼‰
        for key in metadata_keys:
            if key in batch:
                new_batch[key] = batch[key]
        
        return new_batch
    
    def predict_dataloader(self):
        def collate_single_sample(batch):
            """æ¯ä¸ªæ ·æœ¬å•ç‹¬å¤„ç†ï¼Œä¸å †å ï¼ˆå› ä¸ºå°ºå¯¸å¯èƒ½ä¸åŒï¼‰"""
            # batch æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª sample dict
            # ç”±äº batch_size=1ï¼Œç›´æ¥è¿”å›ç¬¬ä¸€ä¸ªå…ƒç´ 
            if len(batch) == 1:
                sample = batch[0]
                # ä¸ºå¼ é‡æ·»åŠ  batch ç»´åº¦
                for key in ["image_t", "image_tm1", "dem_t", "dem_tm1"]:
                    if key in sample and torch.is_tensor(sample[key]):
                        sample[key] = sample[key].unsqueeze(0)  # [C,H,W] -> [1,C,H,W]
                return sample
            else:
                # å¦‚æœ batch_size > 1ï¼Œä½¿ç”¨ stack_samplesï¼ˆä½†è¦æ±‚å°ºå¯¸ç›¸åŒï¼‰
                return stack_samples(batch)

        return DataLoader(
            self.dataset,
            sampler=self.predict_sampler,
            num_workers=self.num_workers,
            batch_size=1,  # âœ… å¼ºåˆ¶ batch_size=1ï¼Œæ¯ä¸ªå½±åƒå•ç‹¬å¤„ç†
            collate_fn=collate_single_sample,
        )
    
    # def predict_dataloader(self):
    #     def collate_and_filter(batch):
    #         # ç”¨ torchgeo çš„ stack_samples åšé»˜è®¤èšåˆ
    #         batch = stack_samples(batch)
    #         # åªä¿ç•™å¼ é‡å­—æ®µ
    #         keep = ["image_t", "image_tm1", "dem_t", "dem_tm1", "bbox", "path", "crs", "image"]
    #         batch_filtered={}

    #         for k in keep:
    #             if k in batch:
    #                 batch_filtered[k] = batch[k]
            
    #         return batch_filtered
    #         # batch_tensors = {k: v for k, v in batch.items() if k in keep and torch.is_tensor(v)}
    #         # return batch_tensors

    #     return DataLoader(
    #         self.dataset,
    #         sampler=self.predict_sampler,
    #         num_workers=self.num_workers,
    #         batch_size=self.batch_size,
    #         collate_fn=collate_and_filter,
    #     )